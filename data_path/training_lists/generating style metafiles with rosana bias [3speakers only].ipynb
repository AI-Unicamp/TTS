{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039bbcd3",
   "metadata": {},
   "source": [
    "# Testing bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0937e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "df = pd.read_csv('mp_styles_train.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['phonetic_transcription'].values[0])\n",
    "ipd.Audio(df['wav_path'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b6ed89",
   "metadata": {},
   "source": [
    "# Testing pitch change bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb43a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -20\n",
    "y, sr = librosa.load(df['wav_path'].values[n])\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215582bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y*10000.1, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e793fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03130413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import numpy as np\n",
    "\n",
    "snd = parselmouth.Sound(df['wav_path'].values[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a350769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_steps: float = 0.01\n",
    "pitch_floor: float = 75\n",
    "pitch_ceil: float = 600\n",
    "\n",
    "## Customize\n",
    "formant_shift= 1.0\n",
    "pitch_shift = 0.5\n",
    "pitch_range = 1.\n",
    "duration_factor = 1.\n",
    "\n",
    "pitch = parselmouth.praat.call(\n",
    "    snd, 'To Pitch', pitch_steps, pitch_floor, pitch_ceil)\n",
    "ndpit = pitch.selected_array['frequency']\n",
    "# if all unvoiced\n",
    "nonzero = ndpit > 1e-5\n",
    "# if nonzero.sum() == 0:\n",
    "#     return snd.values[0]\n",
    "# if voiced\n",
    "median, minp = np.median(ndpit[nonzero]).item(), ndpit[nonzero].min().item()\n",
    "# scale\n",
    "updated = median * pitch_shift\n",
    "scaled = updated + (minp * pitch_shift - updated) * pitch_range\n",
    "# for preventing infinite loop of `Change gender`\n",
    "# ref:https://github.com/praat/praat/issues/1926\n",
    "if scaled < 0.:\n",
    "    pitch_range = 1.\n",
    "out, = parselmouth.praat.call(\n",
    "    (snd, pitch), 'Change gender',\n",
    "    formant_shift,\n",
    "    median * pitch_shift,\n",
    "    pitch_range,\n",
    "    duration_factor).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(out, rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05938b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f0(wav_numpy, p_len=None, sampling_rate=44100,\n",
    "    hop_length=512, voice_thresh = 0.3):\n",
    "    import parselmouth\n",
    "    x = wav_numpy\n",
    "    if p_len is None:\n",
    "        p_len = x.shape[0]//hop_length\n",
    "    else:\n",
    "        assert abs(p_len-x.shape[0]//hop_length) < 4, \"pad length error\"\n",
    "    time_step = hop_length / sampling_rate * 1000\n",
    "    f0_min = 50\n",
    "    f0_max = 1100\n",
    "    f0 = parselmouth.Sound(x, sampling_rate).to_pitch_cc(\n",
    "        time_step=time_step / 1000, voicing_threshold=voice_thresh,\n",
    "        pitch_floor=75, pitch_ceiling=1100).selected_array['frequency']\n",
    "\n",
    "    pad_size=(p_len - len(f0) + 1) // 2\n",
    "    if(pad_size>0 or p_len - len(f0) - pad_size>0):\n",
    "        f0 = np.pad(f0,[[pad_size,p_len - len(f0) - pad_size]], mode='constant')\n",
    "    return f0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b727acc",
   "metadata": {},
   "source": [
    "## Lets compute range of F0 from Rosana, and Adriana CAN x CPQD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_stats = df.copy()\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "medians = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    y, sr = librosa.load(df['wav_path'].values[i])\n",
    "    mean = np.mean(compute_f0(y))\n",
    "    std = np.std(compute_f0(y))\n",
    "    median = np.median(compute_f0(y))\n",
    "        \n",
    "    means.append(mean)\n",
    "    stds.append(std)\n",
    "    medians.append(medians)\n",
    "    \n",
    "f0_stats['f0_mean'] = means\n",
    "f0_stats['f0_std'] = stds\n",
    "f0_stats['f0_median'] = medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag if data is from canada or CPQD\n",
    "f0_stats['is_canada'] = \"eps_\" in f0_stats['wav_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3b61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8795a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72806f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e734c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6b87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172d80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c10ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c736827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a30cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b068742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_paths = []\n",
    "\n",
    "for f in os.listdir('/l/disk1/awstebas/data/TTS/speaker-adriana/'):\n",
    "    if(\"eps_neutro\" in f or \"eps_animado\" in f or \"eps_rispido\" in f or 'eps_acolhedor' in f):\n",
    "        if(f[:4] != \"sint\"):\n",
    "            eps_paths.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f309bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code above should result in this cell output. Maybe you should change the above code\n",
    "eps_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p = '/l/disk1/awstebas/data/TTS/speaker-adriana/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING FOR WAV22 FOLDER IN EACH STYLE\n",
    "c = True\n",
    "t = True\n",
    "for e in eps_paths:\n",
    "    if('wav22' not in os.listdir(data_p + e)):\n",
    "        print(\"There is no 'wav22' folder in \", e)\n",
    "        c = False\n",
    "    if('transcricao' not in os.listdir(data_p + e)):\n",
    "        print(\"There is no 'transcricao' folder in \", e)\n",
    "        t = False\n",
    "        \n",
    "if(c == True):\n",
    "    print(\"All folders have wav22 file\")\n",
    "\n",
    "if(t == True):\n",
    "    print(\"All folders have transcricao file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c0ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING TEXT STRUCTURE\n",
    "\n",
    "ex = '/l/disk1/awstebas/data/TTS/speaker-adriana/eps_rispido_aco/transcricao/eps_rispido_aco.txt'\n",
    "\n",
    "with open(ex, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line.split(':'))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining get_wav and text\n",
    "\n",
    "styles = []\n",
    "wavs = []\n",
    "texts = []\n",
    "for e in eps_paths:\n",
    "    local_dir = data_p + e\n",
    "    \n",
    "    transc_path = local_dir + '/transcricao/' + e + '.txt'\n",
    "    with open(transc_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            splitted = line.split(':')\n",
    "            \n",
    "            wpath = local_dir + '/wav22/' + splitted[0] + '.wav'\n",
    "           \n",
    "            if(os.path.isfile(wpath)):\n",
    "                wavs.append(wpath)\n",
    "\n",
    "                texts.append(splitted[1][1:-1])\n",
    "\n",
    "                style = e.split('_')[1]\n",
    "                styles.append(style)\n",
    "            else:\n",
    "                print(f'{wpath} is not a file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01361d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7238c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phones(txt):\n",
    "    \n",
    "    with open('tmp.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(txt)\n",
    "    \n",
    "    cmd = '/workspace/tool_language/tool_language -l /workspace/tool_language/libptbr.so.4.6.0 -p /workspace/tool_language/ -i tmp.txt -o tmp_pnh.txt --phonemes -s'\n",
    "    \n",
    "    os.system(cmd)\n",
    "    \n",
    "    with open ('tmp_pnh.txt', \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    return lines[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ce9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_phones(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = []\n",
    "\n",
    "for t in texts:\n",
    "    phones.append(get_phones(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = ['adriana'] * len(phones)\n",
    "df = pd.DataFrame({'norm_text': texts,\n",
    "                   'phonetic_transcription': phones,\n",
    "                   'wav_path': wavs,\n",
    "                   'style': styles,\n",
    "                   'speaker': speakers})\n",
    "\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phonetic_transcription'].values[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7948f",
   "metadata": {},
   "source": [
    "# Now lets particionate in train, val and test...\n",
    "\n",
    "Where, test set will be 50% paired samples among all styles and the other 50% will be non-paired samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba55ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a flag in which we have same phonemes\n",
    "\n",
    "gp = df.groupby('phonetic_transcription').count().reset_index().sort_values(by='speaker', ascending= False)\n",
    "gp['len'] = gp.phonetic_transcription.str.len()\n",
    "gp.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb0418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['phonetic_transcription'] == gp.phonetic_transcription.values[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7118afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "f =df[df['phonetic_transcription'] == gp.phonetic_transcription.values[2]]['wav_path'].values[-1]\n",
    "IPython.display.Audio(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ee72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "f =df[df['phonetic_transcription'] == gp.phonetic_transcription.values[0]]['wav_path'].values[4]\n",
    "IPython.display.Audio(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "50/5180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129972a4",
   "metadata": {},
   "source": [
    "# Lets get 20 paired and 30 unpaired samples\n",
    "\n",
    "Because, in 20 paired samples we have at least 80 audio samples (1 for each 4 styles_), while in 30 unpaired samples we have only 30 audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e246d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a flag in which we have same phonemes\n",
    "\n",
    "gp = df.groupby('phonetic_transcription').count().reset_index().sort_values(by='speaker', ascending= False)\n",
    "gp['len'] = gp.phonetic_transcription.str.len()\n",
    "\n",
    "paired = gp.head(20).phonetic_transcription.values\n",
    "paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a flag in which we have same phonemes\n",
    "\n",
    "gp = df.groupby('phonetic_transcription').count().reset_index().sort_values(by='speaker', ascending= True)\n",
    "gp['len'] = gp.phonetic_transcription.str.len()\n",
    "\n",
    "nonpaired = gp[gp['speaker'] == 1].phonetic_transcription.values\n",
    "len(nonpaired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf359c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "npfilt = df[df.phonetic_transcription.isin(nonpaired)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpaired_neutral = npfilt[npfilt['style'] == 'neutro'].sample(5, random_state = 42).phonetic_transcription.values\n",
    "nonpaired_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpaired_animado = npfilt[npfilt['style'] == 'animado'].sample(5, random_state = 42).phonetic_transcription.values\n",
    "nonpaired_animado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ad9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpaired_acolhedor = npfilt[npfilt['style'] == 'acolhedor'].sample(5, random_state = 42).phonetic_transcription.values\n",
    "nonpaired_acolhedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpaired_rispido = npfilt[npfilt['style'] == 'rispido'].sample(5, random_state = 42).phonetic_transcription.values\n",
    "nonpaired_rispido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpaired_neutral = list(nonpaired_neutral)\n",
    "nonpaired_animado = list(nonpaired_animado)\n",
    "nonpaired_acolhedor = list(nonpaired_acolhedor)\n",
    "nonpaired_rispido = list(nonpaired_rispido)\n",
    "\n",
    "nonpaired = []\n",
    "nonpaired.extend(nonpaired_neutral)\n",
    "nonpaired.extend(nonpaired_animado)\n",
    "nonpaired.extend(nonpaired_rispido)\n",
    "nonpaired.extend(nonpaired_acolhedor)\n",
    "\n",
    "paired = list(paired)\n",
    "len(nonpaired), len(paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just hear some examples if its all right\n",
    "import IPython\n",
    "f =df[df['phonetic_transcription'] == nonpaired_neutral[4]]['wav_path'].values[0]\n",
    "IPython.display.Audio(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa671dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just hear some examples if its all right\n",
    "import IPython\n",
    "f =df[df['phonetic_transcription'] == nonpaired_animado[0]]['wav_path'].values[0]\n",
    "IPython.display.Audio(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just hear some examples if its all right\n",
    "import IPython\n",
    "f =df[df['phonetic_transcription'] == nonpaired_rispido[0]]['wav_path'].values[0]\n",
    "IPython.display.Audio(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just hear some examples if its all right\n",
    "import IPython\n",
    "f =df[df['phonetic_transcription'] == nonpaired_acolhedor[0]]['wav_path'].values[0]\n",
    "IPython.display.Audio(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d4209",
   "metadata": {},
   "source": [
    "Aparentemente tudo certo, vamos agora splitar o conjuntos de teste inteiro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a940ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_paired = df[df.phonetic_transcription.isin(paired)]\n",
    "df_test_paired.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ebc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_paired.value_counts('style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_unpaired = df[df.phonetic_transcription.isin(nonpaired)]\n",
    "df_test_unpaired.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50455e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, lets save files as meta_data format for cpqd_read, which use ';' as separator\n",
    "\n",
    "cols = ['phonetic_transcription', 'wav_path', 'speaker','style']\n",
    "\n",
    "df_test_paired[cols].to_csv('styles_paired_test.csv', index = False, sep=';', encoding = 'utf-8')\n",
    "df_test_unpaired[cols].to_csv('styles_unpaired_test.csv', index = False, sep=';', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1dbc1f",
   "metadata": {},
   "source": [
    "# Now lets define our \"rest\" dataset and split in train and val randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_to_exclude = []\n",
    "total_to_exclude.extend(nonpaired)\n",
    "total_to_exclude.extend(paired)\n",
    "\n",
    "df_rest = df[~df.phonetic_transcription.isin(total_to_exclude)]\n",
    "df_rest.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_rest, test_size = 0.03, stratify=df_rest['style'], random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf31ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def get_durations(wpath):\n",
    "    y, sr = librosa.load(wpath, sr = None)\n",
    "    return len(y)/sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "durs = []\n",
    "for w in df_train['wav_path']:\n",
    "    durs.append(get_durations(w))\n",
    "df_train['durs'] = durs\n",
    "\n",
    "durs = []\n",
    "for w in df_val['wav_path']:\n",
    "    durs.append(get_durations(w))\n",
    "df_val['durs'] = durs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182120c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.durs.sum()/3600, df_val.durs.sum()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train per speaker\n",
    "df_train.groupby('style').agg({'durs': 'sum'})/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val per speaker\n",
    "df_val.groupby('style').agg({'durs': 'sum'})/3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b378ab6",
   "metadata": {},
   "source": [
    "# Now, getting the train and val dataset from universal list and getting only 3 speakers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2952f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train = pd.read_csv(\"universal_cpqd_train.csv\", encoding= 'utf-8', sep=';')\n",
    "u_val = pd.read_csv(\"universal_cpqd_val.csv\", encoding= 'utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train['style'] = 'neutro'\n",
    "u_val['style'] = 'neutro'\n",
    "\n",
    "speakers_in = ['adriana','chiquinho','rosana']\n",
    "\n",
    "u_train = u_train[u_train['speaker'].isin(speakers_in)]\n",
    "u_val = u_val[u_val['speaker'].isin(speakers_in)]\n",
    "\n",
    "u_train.speaker.unique(), u_val.speaker.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec(wpath):\n",
    "    return wpath.split('/')[7]\n",
    "\n",
    "recs = []\n",
    "for w in u_train.wav_path:\n",
    "    recs.append(get_rec(w))\n",
    "u_train['rec'] = recs\n",
    "\n",
    "recs = []\n",
    "for w in u_val.wav_path:\n",
    "    recs.append(get_rec(w))\n",
    "u_val['rec'] = recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train.rec.unique(), u_val.rec.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train.shape , u_train[u_train.rec.isin(['rf_selecionadas'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train[(u_train.rec.isin(['riqueza_fonetica']))].speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train[(u_train['speaker'].isin(['rosana','chiquinho'])) | ((u_train['speaker'] == 'adriana') & (u_train['rec'] == 'riqueza_fonetica'))].speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82581a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train = u_train[(u_train['speaker'].isin(['rosana','chiquinho'])) | ((u_train['speaker'] == 'adriana') & (u_train['rec'] == 'riqueza_fonetica'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_val.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting only the necessary cols\n",
    "cols = ['phonetic_transcription', 'wav_path', 'speaker','style']\n",
    "\n",
    "u_train = u_train[cols]\n",
    "u_val = u_val[cols]\n",
    "\n",
    "df_train = df_train[cols]\n",
    "df_val = df_val[cols]\n",
    "\n",
    "df_train_tot = pd.concat([df_train, u_train]).reset_index(drop = True)\n",
    "df_val_tot = pd.concat([df_val, u_val]).reset_index(drop = True)\n",
    "\n",
    "df_train_tot.shape, df_val_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c980de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tot.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_tot.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a298ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "durs = []\n",
    "for w in df_train_tot['wav_path']:\n",
    "    durs.append(get_durations(w))\n",
    "df_train_tot['durs'] = durs\n",
    "\n",
    "durs = []\n",
    "for w in df_val_tot['wav_path']:\n",
    "    durs.append(get_durations(w))\n",
    "df_val_tot['durs'] = durs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf72915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tot.durs.sum()/3600, df_val_tot.durs.sum()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train per speaker\n",
    "df_train_tot.groupby('style').agg({'durs': 'sum'})/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e316fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train per speaker\n",
    "df_train_tot.groupby('speaker').agg({'durs': 'sum'})/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fa7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['phonetic_transcription', 'wav_path', 'speaker','style']\n",
    "\n",
    "df_train_tot[cols].to_csv('mp_styles_train.csv', index = False, sep=';', encoding = 'utf-8')\n",
    "df_val_tot[cols].to_csv('mp_styles_val.csv', index = False, sep=';', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74b7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
